{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJang770/GitHub_tutorial/blob/main/pytorch/2_PyTorch_with_TORCHVISION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arRPLw__9ccP"
      },
      "source": [
        "# Torch vision example\n",
        "Source: https://www.learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2u5VkGhr9ccQ"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "import torch\n",
        "\n",
        "# Let us look at the Deep learning architectures implemented in the torch vision library.\n",
        "dir(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFbb6WLR9ccR"
      },
      "source": [
        "Notice that there is one entry called **AlexNet** and one called **alexnet**. The capitalised name refers to the Python class (AlexNet) whereas alexnet is a convenience function that returns the model instantiated from the AlexNet class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOAJ4ZwA9ccR"
      },
      "outputs": [],
      "source": [
        "alexnet = models.alexnet(pretrained=True) # This will download the weights for the network first time it is run!\n",
        "alexnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxKVFlek9ccR"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from skimage import io, transform\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# img = io.imread('img/cat.jpg')\n",
        "img = Image.open('img/cat.jpg')\n",
        "#img = Image.open('img/hamster.jpg')\n",
        "#img = Image.open('img/centipede.jpg')\n",
        "# plt.imshow(img)\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7ieLM7J9ccR"
      },
      "outputs": [],
      "source": [
        "s = 255\n",
        "img.resize((256,256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgSO12im9ccS"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "transform = transforms.Compose([        # Defining a variable transforms\n",
        " transforms.Resize(256),                # Resize the image to 256×256 pixels\n",
        " transforms.CenterCrop(224),            # Crop the image to 224×224 pixels about the center\n",
        " transforms.ToTensor(),                 # Convert the image to PyTorch Tensor data type\n",
        " transforms.Normalize(                  # Normalize the image\n",
        " mean=[0.485, 0.456, 0.406],            # Mean and std of image as also used when training the network\n",
        " std=[0.229, 0.224, 0.225]\n",
        " )])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grBvv9tV9ccS"
      },
      "outputs": [],
      "source": [
        "img_t = transform(img)\n",
        "img_t.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOscIh9l9ccS"
      },
      "outputs": [],
      "source": [
        "batch_t = torch.unsqueeze(img_t, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fx3vuzAx9ccS"
      },
      "outputs": [],
      "source": [
        "alexnet.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuM9HMRG9ccS"
      },
      "outputs": [],
      "source": [
        "out = alexnet(batch_t)\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFvXn_Rq9ccS"
      },
      "outputs": [],
      "source": [
        "with open('imagenet_classes.txt') as f:\n",
        "  classes = [line.strip() for line in f.readlines()]\n",
        "print(\"Number of classes: {}\".format(len(classes)))\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtoaEw_R9ccS"
      },
      "outputs": [],
      "source": [
        "_, indices = torch.sort(out, descending=True)\n",
        "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "[(classes[idx], percentage[idx].item()) for idx in indices[0][:10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMCmBRFo9ccT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}